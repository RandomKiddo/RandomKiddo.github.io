<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Hyde</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2026-01-22T20:37:00-05:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Mark Otto</name>
   <email></email>
 </author>

 
 <entry>
   <title>CURE: Crude Traceback of IC4665 Cluster</title>
   <link href="http://localhost:4000/2025/12/12/cure/"/>
   <updated>2025-12-12T00:00:00-05:00</updated>
   <id>http://localhost:4000/2025/12/12/cure</id>
   <content type="html">&lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;
&lt;/script&gt;

&lt;div class=&quot;message&quot;&gt;
    &lt;i&gt;CURE: Class-based Undergraduate Research Experience&lt;/i&gt;. &lt;br /&gt;
    &lt;br /&gt;
    Throughout this project, the traceback of the IC4665 star cluster was investigated to see the characteristics of the cluster millions of years ago. This was done primarily by leveraging Gaia SQL queries on proper motion and “rewinding” these proper motions in the opposite direction to find the right ascension and declination of where all the stars were previously located. We also make use of &lt;a href=&quot;https://simbad.u-strasbg.fr/simbad/sim-basic?Ident=IC4665https://simbad.u-strasbg.fr/simbad/sim-basic?Ident=IC4665&quot;&gt;Simbad&lt;/a&gt; data to do this traceback analysis. Our initial prediction would be that the cluster members would be closer together in the past then they are today. We do not precisely see this, as we see that the cluster throughout time tends to stay together, but some members spread out slightly in the past. This, however, can be understood due to the constraints on our traceback calculations and the fact that we are not considering any gravitational forces. We also make an animation of the cluster traceback utilizing prior knowledge and open-source code from Drs. Furnstahl and Brandenburg for &lt;a href=&quot;https://github.com/jdbrice/5300-JB/tree/mainhttps://github.com/jdbrice/5300-JB/tree/main&quot;&gt;Physics 5300&lt;/a&gt;.
&lt;/div&gt;

&lt;h3 id=&quot;description&quot;&gt;Description&lt;/h3&gt;

&lt;p&gt;As a part of the Astronomy 3350 course (Methods of Astronomical Observation and Data Analysis), our last &lt;em&gt;computational essay&lt;/em&gt; involved doing an actual research project (of our choosing) on the IC4665 cluster. Our group chose the “Traceback” project, which involved identifying cluster members by tracing back the motion of the cluster using Right Ascension and Declination values. Since this project was intended to be a small undergraduate research experience, the results and information was unknown.&lt;/p&gt;

&lt;h3 id=&quot;theory&quot;&gt;Theory&lt;/h3&gt;

&lt;p&gt;The traceback of the cluster elements was done very crudely. We used public Simbad data to bound data from Gaia to the rough area of the cluster using parallax, R.A., and Dec. We used an SQL query via&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-py&quot;&gt;top_n = 10000  # how many values we want to fetch from the data

query = &quot;&quot;&quot;SELECT TOP %d
source_id, ra, ra_error, dec, dec_error, parallax, parallax_error, pmra, pmra_error, pmdec, pmdec_error 
FROM gaiadr3.gaia_source
where parallax &amp;gt;= %.2f and parallax &amp;lt;= %.2f and ra &amp;gt;= %.2f
and ra &amp;lt;= %.2f and dec &amp;gt;= %.2f and dec &amp;lt;= %.2f
&quot;&quot;&quot; % (top_n, parallax_min, parallax_max, ra_min, ra_max, dec_min, dec_max)
query  # Let&apos;s see what the query looks like
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using Pandas, we manipulated the data, and defined how we were going to do the traceback. If \(q\) is the given R.A. or Dec. in degrees, and \(\mu_q\) is the &lt;em&gt;proper motion&lt;/em&gt; R.A. or Dec. in mas/yr, and \(T\) is the time period in years, we can trace our result back for that coordinate value (R.A. or Dec. respectively) via the formula&lt;/p&gt;

\[{\rm Traced\ Result} = \frac{(3.6 \times10^6\ {\rm mas})q - \mu_q T}{3.6\times10^6\ {\rm mas}/1^{\circ}}\]

&lt;p&gt;We created a Python function for this, where we can insert \(n\)-million years to trace the result. We then used Pandas Series analysis to create new columns of the traced motion, and also simultaneously traced the location of the cluster by using Simbad data and using the traceback function. We noted based on &lt;a href=&quot;https://en.wikipedia.org/wiki/IC_4665&quot;&gt;Wikipedia&lt;/a&gt; data that IC4665 is expected to be roughly 55 million years old, so we recognize that we shouldn’t go past that amount, and that 1 million year timesteps are adequate time steps. After tracing back 10 million years, we used Pandas analysis to identify members close to the cluster center, and label those as being members of the cluster. This allowed us to create the animations in the next section, separating cluster members from non-members.&lt;/p&gt;

&lt;h3 id=&quot;animations&quot;&gt;Animations&lt;/h3&gt;

&lt;p&gt;We made animations of the system using the adapted code from &lt;a href=&quot;https://github.com/jdbrice/5300-JB/tree/mainhttps://github.com/jdbrice/5300-JB/tree/main&quot;&gt;Physics 5300&lt;/a&gt; (Theoretical Mechanics). In doing so we can create two styles of animations of the cluster. One keeps the axes fixed, and one dynamically updates the axes to follow the cluster. The cyan elements are the cluster elements, while the rest are background elements. This is the animation with the fixed axes:&lt;/p&gt;

&lt;video width=&quot;320&quot; height=&quot;240&quot; controls=&quot;&quot;&gt;
  &lt;source src=&quot;/vid/animation.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;

&lt;p&gt;The following is the dynamic axes animation:&lt;/p&gt;

&lt;video width=&quot;320&quot; height=&quot;240&quot; controls=&quot;&quot;&gt;
  &lt;source src=&quot;/vid/animation2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
&lt;/video&gt;

&lt;h3 id=&quot;limitations&quot;&gt;Limitations&lt;/h3&gt;

&lt;p&gt;From looking at the above animations, we can do some more official analysis. We see that the cluster, in general, moves together throughout time which &lt;em&gt;is&lt;/em&gt; good and what we expect. From the first animation, we can see that the cluster is a bit more clustered, but it’s not as clustered as we would generally expect. Especially, with the second animation, some cluster elements appear to get much further apart as you go back in time. This, however, is due to the crude way we traced the cluster members back, and we also consider no gravitational impacts, which would help attract the objects together. Also, due to lack of Gaia data, did not consider measurements like radial velocity, as most Gaia data points did not have this value readily available. Despite that, by seeing that we do get the general cluster moves together, that is a good result for this loose analysis.&lt;/p&gt;

&lt;h3 id=&quot;data-notice&quot;&gt;Data Notice&lt;/h3&gt;

&lt;p&gt;Because this cluster and its data and properties are still actively being investigated, this project is &lt;em&gt;not&lt;/em&gt; publicly hosted on Github or other hosting platforms. However, the project &lt;code&gt;.ipynb&lt;/code&gt; file used for submission for the course may be distributed upon reasonable request.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kapitza Pendulum Analysis</title>
   <link href="http://localhost:4000/2025/12/09/kapitza/"/>
   <updated>2025-12-09T00:00:00-05:00</updated>
   <id>http://localhost:4000/2025/12/09/kapitza</id>
   <content type="html">&lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;
&lt;/script&gt;

&lt;div class=&quot;message&quot;&gt;
  The following project involves the numerical analysis and manim animation of a Kapitza pendulum system as a part of a theoretical mechanics course final project. Specifically, we use Manim animations and Hopf bifurcation analysis to inspect the stability of the inverted position of the pendulum in the high-driving, low-amplitude regime. This is done with a mix of analytical and numerical methods. 
&lt;/div&gt;

&lt;h3 id=&quot;implementations&quot;&gt;Implementations&lt;/h3&gt;

&lt;p&gt;Reading the &lt;a href=&quot;https://github.com/RandomKiddo/KapitzaPendulumAnalysis/blob/master/src/Project.ipynb&quot;&gt;Project notebook file&lt;/a&gt; provides a comprehensive step-by-step breakdown of the project. Inspecting the various &lt;code&gt;.py&lt;/code&gt; files shows the different numerical solving methods used to solve this system.&lt;/p&gt;

&lt;p&gt;The project does the following:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Derives the Lagrangian, equations of motion, and effective potential for the Kapitza pendulum system, while inspecting the high-driving, low-amplitude regime.&lt;/li&gt;
  &lt;li&gt;Implements numerical methods to solve the system and check that turning off the driving components recovers the simple pendulum.&lt;/li&gt;
  &lt;li&gt;Dynamic widget analysis of the system with varying parameters.&lt;/li&gt;
  &lt;li&gt;\(U(\phi,t)\) and \(U_{\rm eff}(\phi)\) comparisons for high-driving, low-amplitude regime, with separate PDF derivation.&lt;/li&gt;
  &lt;li&gt;Manim animations of the system, with normalized state space axis as well.&lt;/li&gt;
  &lt;li&gt;Chaos and bifurcation analysis: using Liapunov exponent to judge chaos. Manim animations of two pendula for chaos, with animated Liapunov exponent graph. Hopf bifurcation discrete analysis with checks on stability vs. instability of the vertical position using the bifurcation plot. Further analysis on the low-amplitude area, showing periodic motion but no chaos.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Included in the Github repository:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;All project files: the project Jupyter notebook, the PDF derivation file, any &lt;code&gt;.py&lt;/code&gt; numerical files, and the outputted images.&lt;/li&gt;
  &lt;li&gt;The Conda environment used for the project, built for M-architecture OS.&lt;/li&gt;
  &lt;li&gt;The presentation file given as a part of this project.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Manim animations are hosted in the releases, as they are big, hosted in the &lt;code&gt;videos.zip&lt;/code&gt; file in each release description. One example is shown below, but in order to get it to display, it has been converted to a gif, which greatly reduces its overall quality. It is recommended to download the zip for higher-fidelity animations. The zip file is &lt;a href=&quot;https://github.com/RandomKiddo/KapitzaPendulumAnalysis/releases/tag/beta1.1&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here is the (low quality) gif: &lt;br /&gt;
&lt;img src=&quot;/imgs/example.gif&quot; alt=&quot;Example Animation as Low-Quality Gif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/KapitzaPendulumAnalysis&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>AI Docking Port Locator and Distance Regressor for the ISS</title>
   <link href="http://localhost:4000/2025/02/23/hackai25/"/>
   <updated>2025-02-23T00:00:00-05:00</updated>
   <id>http://localhost:4000/2025/02/23/hackai25</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create a project for HackAI 2025 at OSU regarding AI docking port location and distance regression for the International Space Station.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Utilizing the data, a multi-headed network (MHN) was built on the top layer of the MobileNetV3Small architecture. The MHN had three heads, each head regressing one of three values: the distance to the ISS, the x-coordinate of the docking port, or the y-coordinate of the docking port. After training, the best model was saved and then used to create a three-dimensional visualization showing the line the SpaceX Dragon capsule would need to take to dock with the ISS. An animation was made of this visualization. This visualization utilized public-access STL files of the ISS and Dragon capsule. &lt;br /&gt;&lt;br /&gt;
  &lt;b&gt;This project won 3rd place in the competition.&lt;/b&gt;
&lt;/div&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;We wanted to create an open-source docking system that can be generalized for different spacecraft. This would aid in the flight process of docking capsules to space stations and would allow for astronauts to direct their attention to other aspects outside of docking. This project also allows for the generalization of docking, showing that it would be possible to do other similar docking tasks with the right data (i.e., automated parking, ship docking, airplane-to-gate travel, etc.)&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;data&quot;&gt;Data&lt;/h3&gt;

&lt;p&gt;The data is a set of 10,000 images of the ISS with labeled distance values and the location of docking port (albeit in a less-usable format). The data came from &lt;a href=&quot;https://www.kaggle.com/datasets/msafi04/iss-docking-dataset/data&quot;&gt;Kaggle&lt;/a&gt;. It was originally part of an AICrowd challenge.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;the-model&quot;&gt;The Model&lt;/h3&gt;

&lt;p&gt;After tuning the model, we arrived on the following MHN top layer on the MobileNetV3Small architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/model.png&quot; alt=&quot;Model Top Layer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We trained the model for 50 epochs implementing early stopping and model checkpoint callbacks to stop the training early if the validation loss stopped decreasing (started to overfit), and to only save the best model based on validation loss. Since this was an MHN, we had three loss functions to minimize, one for each head. We chose MAE for all three heads because we are working with distances. The total loss of the model was a weighted sum of these three individual losses, the weights being tuned through trial-and-error. The result was the following loss graph:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/loss5.png&quot; alt=&quot;Loss Graph&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;visualization&quot;&gt;Visualization&lt;/h3&gt;

&lt;p&gt;Training the model yielded the best model to use for visualization and prediction. Utilizing public-access STL files of the ISS and SpaceX Dragon capsule, we were able to create a 3D visualization in python of the capsule and ISS in 3D-space, and the line the capsule needs to take to dock, using the predictions from the model. Using this visualization, we made an animation showcasing the results of the model. The animation is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/test.gif&quot; alt=&quot;Visualization Animation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/HackAI2025&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Book Recommendation System Using Goodreads Dataset</title>
   <link href="http://localhost:4000/2024/12/12/goodreads/"/>
   <updated>2024-12-12T00:00:00-05:00</updated>
   <id>http://localhost:4000/2024/12/12/goodreads</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create an AI book recommendation system based on the Goodreads raw review dataset for spoiler detection.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; See below. &lt;i&gt;Project work is still ongoing&lt;/i&gt;
&lt;/div&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;This project was part of a Physics 5680 (Big Data Analytics for Physics) class. The project was to create an AI book recommendation system based on the Goodreads dataset. This was a pre-defined project choice out of many from the course. Below is a pipeline of the project.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/pipeline.png&quot; alt=&quot;Pipeline&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;report&quot;&gt;Report&lt;/h3&gt;

&lt;p&gt;A report was required as part of the project. The report outlines all aspects of the project. It is attached below. The report includes information like the training of BERT-Tiny, the confusion matrix, the pipeline, the collaborative filtering, and the results of the project.&lt;/p&gt;

&lt;iframe src=&quot;/pdfs/report.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;h3 id=&quot;project-ipynb&quot;&gt;Project IPYNB&lt;/h3&gt;

&lt;p&gt;Below is the PDF version of the Jupyter Notebook creating the project. It is attached below for viewing.&lt;/p&gt;

&lt;iframe src=&quot;/pdfs/Project2.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/BookRecommendationAI&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dementia Classification AI</title>
   <link href="http://localhost:4000/2024/09/28/dementia/"/>
   <updated>2024-09-28T00:00:00-04:00</updated>
   <id>http://localhost:4000/2024/09/28/dementia</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Revisit the project for OSU Hack AI 2024 and make the model not overfit.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Stacked layers of 61 images of an MRI scan into 3D tensors and build a Tensorflow functional model and trained it using GPU acceleration with an NVIDIA RTX 3060 GPU for a test accuracy of 97.31%.
&lt;/div&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;We wanted to create a classification model that would be able to detect if a patient has dementia based on a set of 61 layers of an MRI scan. If successful, this model could be a support tool for doctors to detect if a patient has dementia. It may not be the definitive way to detect if a patient has dementia, but it could be helpful for doctors to see what the model thinks the patient has and with what confidence.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;data&quot;&gt;Data&lt;/h3&gt;

&lt;p&gt;The data comes from the OASIS Alzheimer’s dataset, a public dataset consisting of 80,000 MRI images. Since 61 MRI images are for a single patient, it means we have over 1300 patients worth of data in this dataset. The data was downloaded from &lt;a href=&quot;https://www.kaggle.com/datasets/ninadaithal/imagesoasis&quot;&gt;Kaggle&lt;/a&gt;, but can also be accessed through the &lt;a href=&quot;https://sites.wustl.edu/oasisbrains/&quot;&gt;OASIS website&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;the-hackai-2024-model&quot;&gt;The HackAI 2024 Model&lt;/h3&gt;

&lt;p&gt;As a part of the OSU AI Club Hack AI 2024, this project was selected by the team to try in complete in the 24-hour hackathon. We downsized the OASIS images and converted them to grayscale to decrease training time and complexity. We stacked each of the 61 MRI images per patient into a 3D tensor as a numpy &lt;code&gt;ndarray&lt;/code&gt; and saved the patient’s 3D MRI scan as an &lt;code&gt;.npz&lt;/code&gt; file. We then amplified some of the moderate dementia and mild dementia samples through duplication, as there weren’t many patients with that classification. We then created a Tensorflow functional model to train on the sample data.&lt;/p&gt;

&lt;p&gt;Although we had a good training accuracy, we had a relatively low testing accuracy (indicating overfitting). Unfortunately, due to not having access to a GPU at the hackathon, we could not GPU accelerate the model, and we did not have enough time to test a simpler model. The training accuracy was in the high 90% range, but the testing accuracy hovered around high 70%.&lt;/p&gt;

&lt;p&gt;Although this repository is being integrated with the Hack AI 2024 repository (meaning the files here will now also be there), the older version of the model can still be found by looking back in the commits &lt;a href=&quot;https://github.com/Nishanth-Kunchala/Hack_AI_2024&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;this-model--results&quot;&gt;This Model &amp;amp; Results&lt;/h3&gt;

&lt;p&gt;We revisited this model to try and create a better model. We continued to use the stacked 3D tensors. The creation file for them is located in the &lt;code&gt;npz_generation.py&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;We created a simpler Tensorflow functional model and GPU accelerated with an NVIDIA RTX 3060 to decrease training time. We added training callbacks of &lt;code&gt;ModelCheckpoint&lt;/code&gt; and &lt;code&gt;EarlyStopping&lt;/code&gt; to save the best possible model. We got a training accuracy of 100% (it isn’t really 100%, it is being rounded) with a testing accuracy of 97.31%, indicating that our model makes much better generalizations this time around.&lt;/p&gt;

&lt;p&gt;Loss and accuracy graphs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/accuracy.png&quot; alt=&quot;Accuracy Graph&quot; /&gt;
&lt;img src=&quot;/screenshots/loss.png&quot; alt=&quot;Loss Graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Confusion matrix:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/confusion_matrix.png&quot; alt=&quot;Confusion Matrix&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/DementiaAI&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Starr Programming Language</title>
   <link href="http://localhost:4000/2024/08/12/starr/"/>
   <updated>2024-08-12T00:00:00-04:00</updated>
   <id>http://localhost:4000/2024/08/12/starr</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create a custom program language written in C++, Flex, and Bison, using LLVM and CMake. 
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Work on this project is ongoing, but the preliminary basic phase has been completed.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example Syntax:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;int one(int a) {
  int x = a * 5
  return x + 3
}

int two() {
  return 5 % 3
}

out(one(12)) // Outputs 63
out(two()) // Outputs 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See the current project on &lt;a href=&quot;https://github.com/RandomKiddo/Starr&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dot on Wheel Animation</title>
   <link href="http://localhost:4000/2023/07/20/dotonwheel/"/>
   <updated>2023-07-20T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/07/20/dotonwheel</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Use Mathematica to create an animation of a dot on a wheel that is rolling at a constant angular velocity.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A wheel with radius R has a constant angular velocity in the -z direction (so the wheel rolls in +x). There is a dot on the wheel a distance p away from the center where p&amp;gt;0. We wish for R&amp;gt;p, but we do explore when p&amp;gt;R and even when p=R. We wish to animate the motion of this dot.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We go through many different results and iterations of animation. The entire process is on the Github tied to the project. This was the final result for R=2, angular velocity of -2, and p=1, and for values of p=2 and p=4.&lt;/p&gt;

&lt;p&gt;p=1:
&lt;img src=&quot;/screenshots/wheelroll3.gif&quot; alt=&quot;Result Gif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;p=2:
&lt;img src=&quot;/screenshots/wheelroll_rho2.gif&quot; alt=&quot;Result Gif 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;p=4:
&lt;img src=&quot;/screenshots/wheelroll_rho4.gif&quot; alt=&quot;Result Gif 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;Note that the original project used a .mov file. This resulting .gif is of lower quality than the original video&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/DotOnWheelAnimation&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Graphene Unsupervised AI Clustering</title>
   <link href="http://localhost:4000/2023/07/14/graphene/"/>
   <updated>2023-07-14T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/07/14/graphene</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create a custom Graphene layer identification model through AI. 
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; &lt;b&gt;Incomplete&lt;/b&gt;, but we get are getting good results for preliminary results. The current work on the project has &lt;i&gt;stalled&lt;/i&gt;.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/graphene.png&quot; alt=&quot;Graphene Clustered&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the current project on &lt;a href=&quot;https://github.com/RandomKiddo/GrapheneMixturing&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;There was a poster presentation associated with this. For discretion regarding the others involved, it has not been included on this website&lt;/sub&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Chocolate - Vanilla Minecraft Extension</title>
   <link href="http://localhost:4000/2023/06/23/chocolate/"/>
   <updated>2023-06-23T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/06/23/chocolate</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Use FabricAPI and Gradle to implement custom behavior into popular game, Minecraft. Work with multiple collaborators through the project. 
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Implementations:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This project implements a lot. To see the custom behavior, check the &lt;a href=&quot;https://github.com/RandomKiddo/ChocolateMod/wiki&quot;&gt;wiki of the repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Addition Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/chocolate.png&quot; alt=&quot;Quartz Spike&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/ChocolateMod&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>House Price AI, Revisited</title>
   <link href="http://localhost:4000/2023/06/22/hpair/"/>
   <updated>2023-06-22T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/06/22/hpair</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Revisit Scikit-Learn House Price predicition AI, and redo it with Tensorflow and excluding location data.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Model with an r&lt;sup&gt;2&lt;/sup&gt; of 0.9946 and is generalized compared to the previous one.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use Pandas to read a csv into a DataFrame. Drop all date and location information and ensure we are only working with numerical data for regression. Deal with null values accordingly, and then split the data into training and testing sets. Define a model that normalizes the data and then trains on 4 ReLU Dense layers of 512 filters with L2 Regularization, and then finish with a singular filter Dense layer. Train the model with a 0.001 learning rate Adam optimzer, using MAE loss. Train the model, and compare the predictions to the true values.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Project File:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/HPAIR.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/HousePriceAI_Revisited&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hemoglobin Binding Project</title>
   <link href="http://localhost:4000/2023/04/17/hemoglobin/"/>
   <updated>2023-04-17T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/04/17/hemoglobin</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Use Jupyter Notebook, LaTeX, and a Matlab Kernel to do data fitting on experimental hemoglobin binding data. Curve fit different models to the data, including the &quot;Non-Cooperative&quot;, Pauling, and Adair models. Run a Monte Carlo simulation on the Adair model, but use brute force for the &quot;Non-Cooperative&quot; and Pauling models. Learn how to derive the models using the grand partition function. Create a poster and present it in LaTeX. Part of Polaris Program at Ohio State.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results: We see that experimentally that hemoglobin oxygen particles are cooperative to some extent. &lt;/u&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Project File:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/Project.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;Derivations:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/HemoglobinDerivations.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;Poster (Obscured):&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/PolarisPosterTrue__Copy_.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/PolarisResearchProject&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PG Stock Price Prediction RNN w/Tensorflow</title>
   <link href="http://localhost:4000/2023/01/27/stockpricernn/"/>
   <updated>2023-01-27T00:00:00-05:00</updated>
   <id>http://localhost:4000/2023/01/27/stockpricernn</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Learn about Neural Networks and RNNs. Get comfortable with Tensorflow. Predict Proctor &amp;amp; Gamble Stock (closing) price.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; A model that is pretty close to the true values of the stock price range predicted (matches shape well, exact values not attained).
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Collect csv data into a Pandas DataFrame. Enumerate the data to make it all numbers and then visualize the data to see what we’re working with. We then reshape and compile the closing price data and do the same to the high and low price values. We concatenate that usiny NumPy into one array and scale the data. We split the data into training and testing sets, and then using TensorFlow and Keras to generate a Sequential model with a LSTM and Dense layer. After compiling it and training it on the training set, we then predict the stock price closing value of the test set, and then graph the results to inspect the accuracy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Snippets:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;PG Stock Price Graph:
&lt;img src=&quot;/screenshots/original.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The RNN Summary:
&lt;img src=&quot;/screenshots/rnnsummary.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Prediction:
&lt;img src=&quot;/screenshots/prediction.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Prediction w/ More Data:
&lt;img src=&quot;/screenshots/predictionplus.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Full Scope of Prediction (Vertical Line Where Prediction Starts):
&lt;img src=&quot;/screenshots/fullscope.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/StockPriceRNN&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Scikit-Learn House Price AI</title>
   <link href="http://localhost:4000/2022/11/28/housepriceai/"/>
   <updated>2022-11-28T00:00:00-05:00</updated>
   <id>http://localhost:4000/2022/11/28/housepriceai</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Get accustomed to Jupyter Notebooks, Scikit-Learn, and simple regression AI modeling. Learn concepts such as normalization, imputation, enumeration, the foundations of CRISP-DM, and the basics of AI modeling. 
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Model with an r&lt;sup&gt;2&lt;/sup&gt; of 0.9999968, but is not general to any house due to location data being factored into the model.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use Pandas to read a csv into a DataFrame. Enumerate the data to get a frame with only numbers. Check for unusable data and use imputation, if needed, to insert data. After inspecting graphs of the data, normalize the data and filter it accordingly. Split the data into training and test sets, and then model the data using KNeighborsRegressor model and train the data. Then, we predict on the test set and measure the error. Finally, we fiddle with the model a bit to find the most accurate one, and then we’re done.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Snippets:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Information Gain on Parameters (VarianceThreshold Not Pictured):
&lt;img src=&quot;/screenshots/informationgain.png&quot; alt=&quot;Information Gain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The r&lt;sup&gt;2&lt;/sup&gt; Values:
&lt;img src=&quot;/screenshots/rsquared.png&quot; alt=&quot;R-Squared Values&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Final Model:
&lt;img src=&quot;/screenshots/model.png&quot; alt=&quot;Final Model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/HousePriceAI&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PandoraPvP</title>
   <link href="http://localhost:4000/2022/07/13/pandora/"/>
   <updated>2022-07-13T00:00:00-04:00</updated>
   <id>http://localhost:4000/2022/07/13/pandora</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;About:&lt;/u&gt; Pandora PvP is a collection of Spigot Minecraft plugins for a designated modded Minecraft public server. The plugins ranged from economy, to utility, and moderation. My personal work was on the development side, where I worked on server optimizations regarding instant block placement, world border creation, staff command logs, and moderator utility commands. Although my time on the project only spanned a couple months, I enjoyed the time I worked on the project.
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;What is Spigot?&lt;/em&gt;:
Minecraft is a video game made in Java (for non-console systems). Spigot is one of many server-hosting options for Minecraft, like Bukkit, Paper, Yatopia, and more. Spigot allows for programmers to create plugins that are loaded with the server as enhancements. Using Spigot’s API, more optimizations and customizability are available for developers.&lt;/p&gt;

&lt;p&gt;This project helped me learn how to organize many tasks into smaller projects, and taught me how to work with more complicated programming systems, like APIs, documentation, and Maven.&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/PandoraPlugins&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Discord Bot Applications</title>
   <link href="http://localhost:4000/2020/05/28/bot/"/>
   <updated>2020-05-28T00:00:00-04:00</updated>
   <id>http://localhost:4000/2020/05/28/bot</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;About:&lt;/u&gt; Discord is a messaging platform with many quality-of-life features. Any developer can create a Discord Bot to add enhancements to the application, which can be fun things (like games) or more useful things (moderation abilities). Starting May 2020, I worked on a Discord Bot called Source Code. In the future, I worked on a larger bot called Psyduck. Both bots were for personal use only, and never became public verified Discord Bots.
&lt;/div&gt;

&lt;p&gt;Through this project I learned a lot about Python development and asynchronous programming. Additionally, I learned about cloud hosting environments like Heroku and Google Cloud VM to host the bot 24/7. I worked a lot with JSON and SQLite as well to store important data. This project help fuel my love for computer science and also taught me how to handle a large-scale project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Screenshots:&lt;/strong&gt; &lt;br /&gt;
&lt;img src=&quot;/imgs/uptime.png&quot; alt=&quot;Uptime&quot; width=&quot;500&quot; /&gt;
&lt;img src=&quot;/imgs/bug.png&quot; alt=&quot;Bug&quot; width=&quot;500&quot; /&gt;
&lt;img src=&quot;/imgs/ping.png&quot; alt=&quot;Ping&quot; width=&quot;500&quot; /&gt;
&lt;img src=&quot;/imgs/status.png&quot; alt=&quot;Status&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See an obscured version of one of my bots (Psyduck) on &lt;a href=&quot;https://github.com/RandomKiddo/MyDiscordBots&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 

</feed>
