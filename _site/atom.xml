<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Hyde</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2025-07-29T15:21:03-04:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Mark Otto</name>
   <email></email>
 </author>

 
 <entry>
   <title>AI Docking Port Locator and Distance Regressor for the ISS</title>
   <link href="http://localhost:4000/2025/02/23/hackai25/"/>
   <updated>2025-02-23T00:00:00-05:00</updated>
   <id>http://localhost:4000/2025/02/23/hackai25</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create a project for HackAI 2025 at OSU regarding AI docking port location and distance regression for the International Space Station.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Utilizing the data, a multi-headed network (MHN) was built on the top layer of the MobileNetV3Small architecture. The MHN had three heads, each head regressing one of three values: the distance to the ISS, the x-coordinate of the docking port, or the y-coordinate of the docking port. After training, the best model was saved and then used to create a three-dimensional visualization showing the line the SpaceX Dragon capsule would need to take to dock with the ISS. An animation was made of this visualization. This visualization utilized public-access STL files of the ISS and Dragon capsule. &lt;br /&gt;&lt;br /&gt;
  &lt;b&gt;This project won 3rd place in the competition.&lt;/b&gt;
&lt;/div&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;We wanted to create an open-source docking system that can be generalized for different spacecraft. This would aid in the flight process of docking capsules to space stations and would allow for astronauts to direct their attention to other aspects outside of docking. This project also allows for the generalization of docking, showing that it would be possible to do other similar docking tasks with the right data (i.e., automated parking, ship docking, airplane-to-gate travel, etc.)&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;data&quot;&gt;Data&lt;/h3&gt;

&lt;p&gt;The data is a set of 10,000 images of the ISS with labeled distance values and the location of docking port (albeit in a less-usable format). The data came from &lt;a href=&quot;https://www.kaggle.com/datasets/msafi04/iss-docking-dataset/data&quot;&gt;Kaggle&lt;/a&gt;. It was originally part of an AICrowd challenge.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;the-model&quot;&gt;The Model&lt;/h3&gt;

&lt;p&gt;After tuning the model, we arrived on the following MHN top layer on the MobileNetV3Small architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/model.png&quot; alt=&quot;Model Top Layer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We trained the model for 50 epochs implementing early stopping and model checkpoint callbacks to stop the training early if the validation loss stopped decreasing (started to overfit), and to only save the best model based on validation loss. Since this was an MHN, we had three loss functions to minimize, one for each head. We chose MAE for all three heads because we are working with distances. The total loss of the model was a weighted sum of these three individual losses, the weights being tuned through trial-and-error. The result was the following loss graph:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/loss5.png&quot; alt=&quot;Loss Graph&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;visualization&quot;&gt;Visualization&lt;/h3&gt;

&lt;p&gt;Training the model yielded the best model to use for visualization and prediction. Utilizing public-access STL files of the ISS and SpaceX Dragon capsule, we were able to create a 3D visualization in python of the capsule and ISS in 3D-space, and the line the capsule needs to take to dock, using the predictions from the model. Using this visualization, we made an animation showcasing the results of the model. The animation is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/test.gif&quot; alt=&quot;Visualization Animation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/HackAI2025&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Book Recommendation System Using Goodreads Dataset</title>
   <link href="http://localhost:4000/2024/12/12/goodreads/"/>
   <updated>2024-12-12T00:00:00-05:00</updated>
   <id>http://localhost:4000/2024/12/12/goodreads</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create an AI book recommendation system based on the Goodreads raw review dataset for spoiler detection.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; See below. &lt;i&gt;Project work is still ongoing&lt;/i&gt;
&lt;/div&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;This project was part of a Physics 5680 (Big Data Analytics for Physics) class. The project was to create an AI book recommendation system based on the Goodreads dataset. This was a pre-defined project choice out of many from the course. Below is a pipeline of the project.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/pipeline.png&quot; alt=&quot;Pipeline&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;report&quot;&gt;Report&lt;/h3&gt;

&lt;p&gt;A report was required as part of the project. The report outlines all aspects of the project. It is attached below. The report includes information like the training of BERT-Tiny, the confusion matrix, the pipeline, the collaborative filtering, and the results of the project.&lt;/p&gt;

&lt;iframe src=&quot;/pdfs/report.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;h3 id=&quot;project-ipynb&quot;&gt;Project IPYNB&lt;/h3&gt;

&lt;p&gt;Below is the PDF version of the Jupyter Notebook creating the project. It is attached below for viewing.&lt;/p&gt;

&lt;iframe src=&quot;/pdfs/Project2.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/BookRecommendationAI&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dementia Classification AI</title>
   <link href="http://localhost:4000/2024/09/28/dementia/"/>
   <updated>2024-09-28T00:00:00-04:00</updated>
   <id>http://localhost:4000/2024/09/28/dementia</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Revisit the project for OSU Hack AI 2024 and make the model not overfit.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Stacked layers of 61 images of an MRI scan into 3D tensors and build a Tensorflow functional model and trained it using GPU acceleration with an NVIDIA RTX 3060 GPU for a test accuracy of 97.31%.
&lt;/div&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;We wanted to create a classification model that would be able to detect if a patient has dementia based on a set of 61 layers of an MRI scan. If successful, this model could be a support tool for doctors to detect if a patient has dementia. It may not be the definitive way to detect if a patient has dementia, but it could be helpful for doctors to see what the model thinks the patient has and with what confidence.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;data&quot;&gt;Data&lt;/h3&gt;

&lt;p&gt;The data comes from the OASIS Alzheimer’s dataset, a public dataset consisting of 80,000 MRI images. Since 61 MRI images are for a single patient, it means we have over 1300 patients worth of data in this dataset. The data was downloaded from &lt;a href=&quot;https://www.kaggle.com/datasets/ninadaithal/imagesoasis&quot;&gt;Kaggle&lt;/a&gt;, but can also be accessed through the &lt;a href=&quot;https://sites.wustl.edu/oasisbrains/&quot;&gt;OASIS website&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;the-hackai-2024-model&quot;&gt;The HackAI 2024 Model&lt;/h3&gt;

&lt;p&gt;As a part of the OSU AI Club Hack AI 2024, this project was selected by the team to try in complete in the 24-hour hackathon. We downsized the OASIS images and converted them to grayscale to decrease training time and complexity. We stacked each of the 61 MRI images per patient into a 3D tensor as a numpy &lt;code&gt;ndarray&lt;/code&gt; and saved the patient’s 3D MRI scan as an &lt;code&gt;.npz&lt;/code&gt; file. We then amplified some of the moderate dementia and mild dementia samples through duplication, as there weren’t many patients with that classification. We then created a Tensorflow functional model to train on the sample data.&lt;/p&gt;

&lt;p&gt;Although we had a good training accuracy, we had a relatively low testing accuracy (indicating overfitting). Unfortunately, due to not having access to a GPU at the hackathon, we could not GPU accelerate the model, and we did not have enough time to test a simpler model. The training accuracy was in the high 90% range, but the testing accuracy hovered around high 70%.&lt;/p&gt;

&lt;p&gt;Although this repository is being integrated with the Hack AI 2024 repository (meaning the files here will now also be there), the older version of the model can still be found by looking back in the commits &lt;a href=&quot;https://github.com/Nishanth-Kunchala/Hack_AI_2024&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;this-model--results&quot;&gt;This Model &amp;amp; Results&lt;/h3&gt;

&lt;p&gt;We revisited this model to try and create a better model. We continued to use the stacked 3D tensors. The creation file for them is located in the &lt;code&gt;npz_generation.py&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;We created a simpler Tensorflow functional model and GPU accelerated with an NVIDIA RTX 3060 to decrease training time. We added training callbacks of &lt;code&gt;ModelCheckpoint&lt;/code&gt; and &lt;code&gt;EarlyStopping&lt;/code&gt; to save the best possible model. We got a training accuracy of 100% (it isn’t really 100%, it is being rounded) with a testing accuracy of 97.31%, indicating that our model makes much better generalizations this time around.&lt;/p&gt;

&lt;p&gt;Loss and accuracy graphs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/accuracy.png&quot; alt=&quot;Accuracy Graph&quot; /&gt;
&lt;img src=&quot;/screenshots/loss.png&quot; alt=&quot;Loss Graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Confusion matrix:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/confusion_matrix.png&quot; alt=&quot;Confusion Matrix&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/DementiaAI&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Starr Programming Language</title>
   <link href="http://localhost:4000/2024/08/12/starr/"/>
   <updated>2024-08-12T00:00:00-04:00</updated>
   <id>http://localhost:4000/2024/08/12/starr</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create a custom program language written in C++, Flex, and Bison, using LLVM and CMake. 
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Work on this project is ongoing, but the preliminary basic phase has been completed.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example Syntax:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;int one(int a) {
  int x = a * 5
  return x + 3
}

int two() {
  return 5 % 3
}

out(one(12)) // Outputs 63
out(two()) // Outputs 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See the current project on &lt;a href=&quot;https://github.com/RandomKiddo/Starr&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dot on Wheel Animation</title>
   <link href="http://localhost:4000/2023/07/20/dotonwheel/"/>
   <updated>2023-07-20T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/07/20/dotonwheel</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Use Mathematica to create an animation of a dot on a wheel that is rolling at a constant angular velocity.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A wheel with radius R has a constant angular velocity in the -z direction (so the wheel rolls in +x). There is a dot on the wheel a distance p away from the center where p&amp;gt;0. We wish for R&amp;gt;p, but we do explore when p&amp;gt;R and even when p=R. We wish to animate the motion of this dot.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We go through many different results and iterations of animation. The entire process is on the Github tied to the project. This was the final result for R=2, angular velocity of -2, and p=1, and for values of p=2 and p=4.&lt;/p&gt;

&lt;p&gt;p=1:
&lt;img src=&quot;/screenshots/wheelroll3.gif&quot; alt=&quot;Result Gif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;p=2:
&lt;img src=&quot;/screenshots/wheelroll_rho2.gif&quot; alt=&quot;Result Gif 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;p=4:
&lt;img src=&quot;/screenshots/wheelroll_rho4.gif&quot; alt=&quot;Result Gif 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;Note that the original project used a .mov file. This resulting .gif is of lower quality than the original video&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/DotOnWheelAnimation&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Graphene Unsupervised AI Clustering</title>
   <link href="http://localhost:4000/2023/07/14/graphene/"/>
   <updated>2023-07-14T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/07/14/graphene</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Create a custom Graphene layer identification model through AI. 
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; &lt;b&gt;Incomplete&lt;/b&gt;, but we get are getting good results for preliminary results. The current work on the project has &lt;i&gt;stalled&lt;/i&gt;.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/graphene.png&quot; alt=&quot;Graphene Clustered&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the current project on &lt;a href=&quot;https://github.com/RandomKiddo/GrapheneMixturing&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sub&gt;There was a poster presentation associated with this. For discretion regarding the others involved, it has not been included on this website&lt;/sub&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Chocolate - Vanilla Minecraft Extension</title>
   <link href="http://localhost:4000/2023/06/23/chocolate/"/>
   <updated>2023-06-23T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/06/23/chocolate</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Use FabricAPI and Gradle to implement custom behavior into popular game, Minecraft. Work with multiple collaborators through the project. 
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Implementations:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This project implements a lot. To see the custom behavior, check the &lt;a href=&quot;https://github.com/RandomKiddo/ChocolateMod/wiki&quot;&gt;wiki of the repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Addition Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/screenshots/chocolate.png&quot; alt=&quot;Quartz Spike&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/ChocolateMod&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>House Price AI, Revisited</title>
   <link href="http://localhost:4000/2023/06/22/hpair/"/>
   <updated>2023-06-22T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/06/22/hpair</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Revisit Scikit-Learn House Price predicition AI, and redo it with Tensorflow and excluding location data.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Model with an r&lt;sup&gt;2&lt;/sup&gt; of 0.9946 and is generalized compared to the previous one.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use Pandas to read a csv into a DataFrame. Drop all date and location information and ensure we are only working with numerical data for regression. Deal with null values accordingly, and then split the data into training and testing sets. Define a model that normalizes the data and then trains on 4 ReLU Dense layers of 512 filters with L2 Regularization, and then finish with a singular filter Dense layer. Train the model with a 0.001 learning rate Adam optimzer, using MAE loss. Train the model, and compare the predictions to the true values.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Project File:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/HPAIR.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/HousePriceAI_Revisited&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hemoglobin Binding Project</title>
   <link href="http://localhost:4000/2023/04/17/hemoglobin/"/>
   <updated>2023-04-17T00:00:00-04:00</updated>
   <id>http://localhost:4000/2023/04/17/hemoglobin</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Use Jupyter Notebook, LaTeX, and a Matlab Kernel to do data fitting on experimental hemoglobin binding data. Curve fit different models to the data, including the &quot;Non-Cooperative&quot;, Pauling, and Adair models. Run a Monte Carlo simulation on the Adair model, but use brute force for the &quot;Non-Cooperative&quot; and Pauling models. Learn how to derive the models using the grand partition function. Create a poster and present it in LaTeX. Part of Polaris Program at Ohio State.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results: We see that experimentally that hemoglobin oxygen particles are cooperative to some extent. &lt;/u&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Project File:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/Project.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;Derivations:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/HemoglobinDerivations.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;Poster (Obscured):&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;/pdfs/PolarisPosterTrue__Copy_.pdf&quot; width=&quot;100%&quot; height=&quot;910px&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/PolarisResearchProject&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PG Stock Price Prediction RNN w/Tensorflow</title>
   <link href="http://localhost:4000/2023/01/27/stockpricernn/"/>
   <updated>2023-01-27T00:00:00-05:00</updated>
   <id>http://localhost:4000/2023/01/27/stockpricernn</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Learn about Neural Networks and RNNs. Get comfortable with Tensorflow. Predict Proctor &amp;amp; Gamble Stock (closing) price.
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; A model that is pretty close to the true values of the stock price range predicted (matches shape well, exact values not attained).
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Collect csv data into a Pandas DataFrame. Enumerate the data to make it all numbers and then visualize the data to see what we’re working with. We then reshape and compile the closing price data and do the same to the high and low price values. We concatenate that usiny NumPy into one array and scale the data. We split the data into training and testing sets, and then using TensorFlow and Keras to generate a Sequential model with a LSTM and Dense layer. After compiling it and training it on the training set, we then predict the stock price closing value of the test set, and then graph the results to inspect the accuracy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Snippets:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;PG Stock Price Graph:
&lt;img src=&quot;/screenshots/original.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The RNN Summary:
&lt;img src=&quot;/screenshots/rnnsummary.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Prediction:
&lt;img src=&quot;/screenshots/prediction.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Prediction w/ More Data:
&lt;img src=&quot;/screenshots/predictionplus.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Full Scope of Prediction (Vertical Line Where Prediction Starts):
&lt;img src=&quot;/screenshots/fullscope.png&quot; alt=&quot;PG Price&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/StockPriceRNN&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Scikit-Learn House Price AI</title>
   <link href="http://localhost:4000/2022/11/28/housepriceai/"/>
   <updated>2022-11-28T00:00:00-05:00</updated>
   <id>http://localhost:4000/2022/11/28/housepriceai</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;Goals:&lt;/u&gt; Get accustomed to Jupyter Notebooks, Scikit-Learn, and simple regression AI modeling. Learn concepts such as normalization, imputation, enumeration, the foundations of CRISP-DM, and the basics of AI modeling. 
  &lt;br /&gt; &lt;br /&gt;
  &lt;u&gt;Results:&lt;/u&gt; Model with an r&lt;sup&gt;2&lt;/sup&gt; of 0.9999968, but is not general to any house due to location data being factored into the model.
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use Pandas to read a csv into a DataFrame. Enumerate the data to get a frame with only numbers. Check for unusable data and use imputation, if needed, to insert data. After inspecting graphs of the data, normalize the data and filter it accordingly. Split the data into training and test sets, and then model the data using KNeighborsRegressor model and train the data. Then, we predict on the test set and measure the error. Finally, we fiddle with the model a bit to find the most accurate one, and then we’re done.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Snippets:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Information Gain on Parameters (VarianceThreshold Not Pictured):
&lt;img src=&quot;/screenshots/informationgain.png&quot; alt=&quot;Information Gain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The r&lt;sup&gt;2&lt;/sup&gt; Values:
&lt;img src=&quot;/screenshots/rsquared.png&quot; alt=&quot;R-Squared Values&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Final Model:
&lt;img src=&quot;/screenshots/model.png&quot; alt=&quot;Final Model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/RandomKiddo/HousePriceAI&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PandoraPvP</title>
   <link href="http://localhost:4000/2022/07/13/pandora/"/>
   <updated>2022-07-13T00:00:00-04:00</updated>
   <id>http://localhost:4000/2022/07/13/pandora</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;About:&lt;/u&gt; Pandora PvP is a collection of Spigot Minecraft plugins for a designated modded Minecraft public server. The plugins ranged from economy, to utility, and moderation. My personal work was on the development side, where I worked on server optimizations regarding instant block placement, world border creation, staff command logs, and moderator utility commands. Although my time on the project only spanned a couple months, I enjoyed the time I worked on the project.
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;What is Spigot?&lt;/em&gt;:
Minecraft is a video game made in Java (for non-console systems). Spigot is one of many server-hosting options for Minecraft, like Bukkit, Paper, Yatopia, and more. Spigot allows for programmers to create plugins that are loaded with the server as enhancements. Using Spigot’s API, more optimizations and customizability are available for developers.&lt;/p&gt;

&lt;p&gt;This project helped me learn how to organize many tasks into smaller projects, and taught me how to work with more complicated programming systems, like APIs, documentation, and Maven.&lt;/p&gt;

&lt;p&gt;See the full project on &lt;a href=&quot;https://github.com/PandoraPlugins&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Discord Bot Applications</title>
   <link href="http://localhost:4000/2020/05/28/bot/"/>
   <updated>2020-05-28T00:00:00-04:00</updated>
   <id>http://localhost:4000/2020/05/28/bot</id>
   <content type="html">&lt;div class=&quot;message&quot;&gt;
  &lt;u&gt;About:&lt;/u&gt; Discord is a messaging platform with many quality-of-life features. Any developer can create a Discord Bot to add enhancements to the application, which can be fun things (like games) or more useful things (moderation abilities). Starting May 2020, I worked on a Discord Bot called Source Code. In the future, I worked on a larger bot called Psyduck. Both bots were for personal use only, and never became public verified Discord Bots.
&lt;/div&gt;

&lt;p&gt;Through this project I learned a lot about Python development and asynchronous programming. Additionally, I learned about cloud hosting environments like Heroku and Google Cloud VM to host the bot 24/7. I worked a lot with JSON and SQLite as well to store important data. This project help fuel my love for computer science and also taught me how to handle a large-scale project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Screenshots:&lt;/strong&gt; &lt;br /&gt;
&lt;img src=&quot;/imgs/uptime.png&quot; alt=&quot;Uptime&quot; width=&quot;500&quot; /&gt;
&lt;img src=&quot;/imgs/bug.png&quot; alt=&quot;Bug&quot; width=&quot;500&quot; /&gt;
&lt;img src=&quot;/imgs/ping.png&quot; alt=&quot;Ping&quot; width=&quot;500&quot; /&gt;
&lt;img src=&quot;/imgs/status.png&quot; alt=&quot;Status&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See an obscured version of one of my bots (Psyduck) on &lt;a href=&quot;https://github.com/RandomKiddo/MyDiscordBots&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 

</feed>
